{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45628d30-bdfd-4ee0-9b7c-9ff92ec32cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1 done\n"
     ]
    }
   ],
   "source": [
    "# ollama serve\n",
    "# ollama pull nomic-embed-text\n",
    "# ollama run jyan1/paligemma-mix-224\n",
    "# ollama run gemma\n",
    "\n",
    "from pymilvus import MilvusClient, FieldSchema, DataType, Collection, connections\n",
    "import ollama\n",
    "\n",
    "conversation = [\n",
    "    \"Alice: Hey, how was your weekend?\",\n",
    "    \"Bob: Pretty good! I went hiking. You?\",\n",
    "    \"Alice: Nice! I just relaxed and watched a few movies.\",\n",
    "    \"Bob: That sounds great. Anything worth recommending?\",\n",
    "    \"Alice: Yeah, 'The Secret Garden' was surprisingly good!\",\n",
    "    \"Bob: I'll check it out. Thanks!\"\n",
    "]\n",
    "\n",
    "records_dict = []\n",
    "for i, line in enumerate(conversation):\n",
    "    records_dict.append(\n",
    "        {\n",
    "            \"id\": i+1,\n",
    "            \"original_text\": line,\n",
    "            \"vector\": ollama.embeddings(model='nomic-embed-text', prompt=line)['embedding']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# print(records_dict)\n",
    "print(\"part 1 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43edf740-a4e7-49db-a4e3-3be6262f1a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymilvus.milvus_client.milvus_client.MilvusClient object at 0x134363610>\n",
      "exists:True\n",
      "collection: <Collection>:\n",
      "-------------\n",
      "<name>: test_textvector_storage\n",
      "<description>: \n",
      "<schema>: {'auto_id': False, 'description': '', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'original_text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 512}}, {'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'enable_dynamic_field': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a milvus collection\n",
    "client = MilvusClient(\n",
    "    uri=\"http://localhost:19530\",\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "print(client)\n",
    "\n",
    "collection_name = \"test_textvector_storage\"\n",
    "exists = client.has_collection(collection_name=collection_name)\n",
    "print(f\"exists:{exists}\")\n",
    "\n",
    "def create_collection(client):\n",
    "    # 3.1. Create schema\n",
    "    schema = MilvusClient.create_schema(\n",
    "        enable_dynamic_field=True,\n",
    "    )\n",
    "    \n",
    "    # 3.2. Add fields to schema\n",
    "    schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n",
    "    schema.add_field(field_name=\"original_text\", datatype=DataType.VARCHAR, max_length=512)\n",
    "    schema.add_field(field_name=\"vector\", datatype=DataType.FLOAT_VECTOR, dim=768)\n",
    "    \n",
    "    # 3.3. Prepare index parameters\n",
    "    index_params = client.prepare_index_params()\n",
    "    \n",
    "    # 3.4. Add indexes\n",
    "    index_params.add_index(\n",
    "        field_name=\"id\",\n",
    "        index_type=\"AUTOINDEX\"\n",
    "    )\n",
    "    \n",
    "    index_params.add_index(\n",
    "        field_name=\"vector\", \n",
    "        index_type=\"AUTOINDEX\",\n",
    "        metric_type=\"COSINE\"\n",
    "    )\n",
    "    \n",
    "    return client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        schema=schema,\n",
    "        index_params=index_params\n",
    "    )\n",
    "        \n",
    "if not exists:\n",
    "    print(create_collection(client))\n",
    "\n",
    "connections.connect(alias=\"default\", host=\"127.0.0.1\", port=\"19530\")\n",
    "\n",
    "collection = Collection(collection_name)\n",
    "collection.load()\n",
    "print(f\"collection: {collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eccd6a0-3ae3-4922-85f2-873961ed9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to insert\n",
    "res = client.insert(\n",
    "    collection_name=collection_name,\n",
    "    data=records_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "775712cd-55ab-403a-acb8-ccd7039bb0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4, 'distance': 0.6763947606086731, 'entity': {'original_text': 'Bob: That sounds great. Anything worth recommending?'}}\n",
      "{'id': 6, 'distance': 0.5386989712715149, 'entity': {'original_text': \"Bob: I'll check it out. Thanks!\"}}\n",
      "{'id': 2, 'distance': 0.494762122631073, 'entity': {'original_text': 'Bob: Pretty good! I went hiking. You?'}}\n"
     ]
    }
   ],
   "source": [
    "# now retrieve the documents based on prompt\n",
    "# question = \"what did everyone do in their weekend?\"\n",
    "question = \"Recommend me something based on what they said\"\n",
    "prompt_vector = ollama.embeddings(model='nomic-embed-text', prompt=question)['embedding']\n",
    "\n",
    "res = collection.search(\n",
    "    anns_field=\"vector\",\n",
    "    data=[prompt_vector],\n",
    "    param={\"nprobe\": 16},\n",
    "    limit=3,\n",
    "    output_fields=[\"original_text\"]\n",
    ")\n",
    "\n",
    "\n",
    "# fusing the gathered information\n",
    "retrieved_documents = \"\"\n",
    "for hits in res:\n",
    "    for hit in hits:\n",
    "        retrieved_documents = retrieved_documents + hit['entity']['original_text'] + \";\"\n",
    "        print(hit)\n",
    "\n",
    "# print(retrieved_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b584abd6-81e9-46b8-8eb5-2975dc981d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on Bob's responses, it's not possible to recommend anything as the conversation does not provide any context or preferences regarding recommendations.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='gemma:7b', messages=[{\n",
    "    'role': 'user', \n",
    "    'content': f\"Answer this question: {question} Based on the information here: {retrieved_documents}\",\n",
    "}])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18d0a5-265f-4786-8455-66e251b09de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
